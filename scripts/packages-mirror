#!/bin/bash
# Copyright (C) 2008-2018 Canonical, Ltd.
# Authors: Kees Cook <kees@ubuntu.com>
#          Jamie Strandboge <jamie@ubuntu.com>
# License: GPLv3
#
# This script pulls down all the supported architectures (those that would
# appear in a sis-generate-usn run) Releases and Packages files.
#
# TODO: perform GPG tests (we're only using this info for component
# matching)
set -e

renice 10 -p $$ >/dev/null
ionice -c 2 -n 7 -p $$

help() {
    cat <<EOM
Usage: packages_mirror [OPTIONS]

  -t               use timestamps (ie, don't update files if they have been
                   updated within the last day)
  -f               when using timestamps, force updating the files
  -v               verbose output
  -V               even more verbose output
  -r RELEASE       only update Ubuntu release (implies -u)
  -p               pull only partner
  -u               pull only ubuntu archive
  -d               pull only debian archive
  -n               dry run
  -D               delete old releases
  -Z               do not create uncompressed copies
EOM
}

use_timestamp="no"
force_timestamp="no"
only_release=
verbose="no"
very_verbose="no"
dry_run="no"
delete_old="no"
uncompress="yes"

pull_ubuntu="yes"
pull_partner="yes"
pull_debian="yes"

while getopts "ftvVnDZpudhr:" opt
do
    case "$opt" in
        f) force_timestamp="yes";;
        t) use_timestamp="yes";;
        v) verbose="yes";;
        V) verbose="yes"
           very_verbose="yes"
           ;;
        r) only_release="$OPTARG"
           pull_partner="no"
           pull_debian="no"
           ;;
        n) dry_run="yes";;
        D) delete_old="yes";;
        Z) uncompress="no";;
        p) pull_ubuntu="no"
           pull_debian="no"
           ;;
        u) pull_partner="no"
           pull_debian="no"
           ;;
        d) pull_partner="no"
           pull_ubuntu="no"
           ;;
        h) help ; exit 0;;
        ?) help;;
    esac
done
shift $((OPTIND - 1))

#ubuntu_archive=se.archive.ubuntu.com
#ubuntu_archive=us.archive.ubuntu.com
ubuntu_archive=archive.ubuntu.com
ports_archive=${ports:-ports.ubuntu.com}
debian_archive=ftp.se.debian.org

. "$HOME"/.ubuntu-cve-tracker.conf

for var in packages_mirror debian_mirror partner_mirror; do
  if [ -z "${!var}" ]; then
    echo "'$var' not defined in ~/.ubuntu-cve-tracker.conf" >&2
    exit 1
  fi
done
ubuntuPath="$packages_mirror"
mkdir -p "$ubuntuPath"
ubuntuPath=$(realpath "$ubuntuPath")

debianPath="$debian_mirror"
mkdir -p "$debianPath"
debianPath=$(realpath "$debianPath")

partnerPath="$partner_mirror"
mkdir -p "$partnerPath"
partnerPath=$(realpath "$partnerPath")

function compressed_ext()
{
    rel="$1"
    ext="xz"

    # Prior releases without any .xz Packages files
    bz2releases='^(precise|trusty|vivid)$'

    if echo "$rel" | cut -d- -f1 | grep -Eq "$bz2releases" ; then
        ext="bz2"
    fi

    echo "$ext"
}

function spew_bin_lines()
{
    rel="$1"
    repo="$2"
    arch="$3"
    ext=$(compressed_ext "$rel")

    echo "dists/$rel/$repo/binary-$arch/Release"
    echo "dists/$rel/$repo/binary-$arch/Packages.$ext"
    echo "dists/$rel/$repo/debian-installer/binary-$arch/Packages.$ext"
}

function spew_src_lines()
{
    rel="$1"
    repo="$2"
    ext=$(compressed_ext "$rel")

    echo "dists/$rel/$repo/source/Release"
    echo "dists/$rel/$repo/source/Sources.$ext"
}

function gen_packages()
{
    release="$1"
    arches="$2"
    repos="$3"

    if [ -z "$repos" ]; then
        repos="main restricted universe multiverse"
    fi

    if [ -n "$only_release" ] && [ "$release" != "$only_release" ]; then
        echo "Skipping '$release' (specified '-r $only_release')" >&2
        return
    fi

    release_list="$release $release-updates $release-security $release-proposed $release-backports"
    for rel in $release_list
    do
        for repo in $repos
        do
            for arch in $arches
            do
                spew_bin_lines $rel $repo $arch
            done
            spew_src_lines $rel $repo
        done
    done
}

function do_uncompress()
{
    filelist="$1"

    if [ "$uncompress" != "yes" ]; then
        return
    fi

    if [ "$verbose" = "yes" ]; then
        echo "Uncompressing..."
    fi

    # Create uncompressed versions too
    while read -r filename
    do
        if ! echo "$filename" | grep -Eq '\.(bz2|xz)$' ; then
            continue
        fi
        ext=$(echo "$filename" | awk -F. '{print $NF}')
        src="$ubuntuPath/$filename"
        dest_dir=$(dirname "$src")
        dest_file=$(basename "$src" ."$ext")
        dest="$dest_dir/$dest_file"

        # Skip missing files (debian-installer)
        if [ ! -r "$src" ]; then
            continue
        fi
        if [ ! -f "$dest" ] || [ "$src" -nt "$dest" ]; then
            case "$ext" in
                bz2) cmd="bzcat";;
                xz) cmd="xzcat";;
                *) cmd="gzcat";;
            esac
            if [ "$verbose" = "yes" ]; then
                echo "$cmd $src > $dest"
            fi
            if [ "$dry_run" != "yes" ]; then
                $cmd "$src" > "$dest"
            fi
        fi
        echo "$dest" >> "$filelist.all"
    done < <(cat "$filelist")
}

function pull_packages()
{
    filelist="$1"
    url="$2"
    dest_dir="$3"

    if [ "$verbose" = "yes" ]; then
        echo "Want to fetch:"
        cat "$filelist"
    fi

    count=1
    num_tries=3
    while [ "$count" -le "$num_tries" ]; do
        # FIXME: how do I get both the return code and stdout into a variable?
        log="$workdir/rsync.log"

        args="-rLpt --files-from=${filelist}"
        if [ "$dry_run" = "yes" ]; then
            args="$args -n"
        fi
        if [ "$verbose" = "yes" ]; then
            args="$args -v"
            if [ "$very_verbose" = "yes" ]; then
                args="$args --progress"
            fi
        else
            args="$args -q"
        fi

        set +e
        if [ "$verbose" = "yes" ]; then
            rsync $args $url $dest_dir/ 2>&1 | tee "$log"
        else
            rsync $args $url $dest_dir/ >"$log" 2>&1
        fi
        rc=$?
        set -e

        # keep trying if not successful (23 is missing files)
        if [ $rc -eq 0 ] || [ $rc -eq 23 ]; then
            break
        fi
        count=$((count + 1))
        if [ "$verbose" = "yes" ]; then
            echo "Try: $count" >&2
        fi
    done
    OUT=$(< "$log" grep -Ev '(debian-installer|^rsync.*code 23)' || true)
    rm -f "$log" "$filelist.pattern" || true

    # Report errors, if any
    if [ -n "$OUT" ]; then
        echo "$OUT"
    fi

    # Generate full pathnames for potential cleanups
    while read -r filename
    do
        echo "$dest_dir/$filename" >>"$filelist.all"
    done < <(cat "$filelist")

    # Some unknown error -- die
    if [ $rc -ne 0 ] && [ $rc -ne 23 ]; then
        return 1
    fi
    # Missing files (rc 23), die only if it's not a debian-installer path
    if [ $rc -eq 23 ] && [ -n "$OUT" ]; then
        return 1
    fi

    # Uncompress
    do_uncompress "$filelist"
}

function do_cleanup() {
    filelist="$1"
    dest_dir="$2"

    # Skip all cleanups (which are repo-wide) for release-specific update.
    if [ -n "$only_release" ]; then
        return
    fi

    if [ "$delete_old" = "yes" ]; then
        if [ "$verbose" = "yes" ]; then
            cmd="xargs -r -n1 echo rm"

            echo "Cleaning up ..."
            find "$dest_dir"/ -type f | grep -Fxvf "$filelist" | $cmd
            find "$dest_dir"/ -empty -type d | ${cmd}dir
        fi
        if [ "$dry_run" != "yes" ]; then
            cmd="xargs -r rm"

            find "$dest_dir"/ -type f | grep -Fxvf "$filelist" | $cmd
            find "$dest_dir"/ -empty -type d | ${cmd}dir
        fi
    fi
}

# do_use_timestamp() returns '0' if timestamp doesn't exist or has been modified
# yesterday or more.
function do_use_timestamp() {
    mtime=0
    if [ -n "$2" ]; then
        mtime="$2"
    fi
    if [ "$use_timestamp" = "no" ] || [ "$force_timestamp" = "yes" ]; then
        return 0
    elif [ ! -e "$1" ]; then
        return 0
    else
        tmp=$(find "$1" -mtime +$mtime)
        if [ -n "$tmp" ]; then
            return 0
        fi
    fi
    local days=$((mtime + 1))
    echo "'$1' exists and was modified within the last $days day(s). Skipping." >&2
    return 1
}

workdir=$(mktemp -d -t packages-mirror-XXXXXX)
trap "rm -rf ${workdir}" EXIT

# Generate the lists of all known ubuntu archives (regular, ports, and partner)
if [ "$pull_ubuntu" = "yes" ] || [ "$pull_partner" = "yes" ]; then
    partner_files="$workdir/partner"
    ubuntu_files="$workdir/ubuntu"
    ports_files="$workdir/ports"

    # Sync Packages for non-ports supported arches
    if [ "$verbose" = "yes" ]; then
        echo "Generating ubuntu arch lists"
    fi

    stable=$(curl -s 'http://changelogs.ubuntu.com/meta-release' | egrep '^(Dist|Supported): ' | grep -B1 '^Supported: 1' | grep ^Dist: | awk '{print $NF}')
    devel=$(curl -s http://archive.ubuntu.com/ubuntu/dists/devel/Release | grep ^Suite | awk '{print $NF}')
    releases=$(echo $stable $devel | xargs -n1 | sort -u | xargs)

    for release in $releases ; do
        archs=$(curl -s "http://$ubuntu_archive/ubuntu/dists/$release/" | grep Contents | awk --field-separator 'Contents-' '{print $2}' | cut -d. -f1)
        gen_packages $release  "$(echo $archs)"           >> "$ubuntu_files"
        gen_packages $release  "$(echo $archs)" partner   >> "$partner_files"
    done

    if [ "$verbose" = "yes" ]; then
        echo "Generating ubuntu ports arch lists"
    fi
    for release in $releases ; do
        archs=$(curl -s "http://$ports_archive/ubuntu-ports/dists/$release/" | grep Contents | awk --field-separator 'Contents-' '{print $2}' | cut -d. -f1)
        gen_packages $release "$(echo $archs)"            >> "$ports_files"
        gen_packages $release "$(echo $archs)" partner    >> "$partner_files"
    done

    if [ "$pull_ubuntu" = "yes" ]; then
        timestamp="${ubuntuPath}.timestamp"
        if [ ! -e "${ubuntuPath}/dists" ] || do_use_timestamp "$timestamp" ; then
            pull_packages "$ubuntu_files" "rsync://$ubuntu_archive/ubuntu" "$ubuntuPath" || echo "FAIL: supported architectures" >&2
            pull_packages "$ports_files" "rsync://$ports_archive/ubuntu-ports" "$ubuntuPath" || echo "FAIL: ports architectures" >&2

            cat "${ubuntu_files}.all" "${ports_files}.all" | sort -u > "$workdir/combined.all"

            do_cleanup "$workdir/combined.all" "$ubuntuPath"

            if [ "$dry_run" != "yes" ]; then
                if [ "$use_timestamp" = "yes" ]; then
                    touch "$timestamp"
                else
                    rm -f "$timestamp"
                fi
            fi
        fi
    fi

    if [ "$pull_partner" = "yes" ]; then
        timestamp="${partnerPath}.timestamp"
        if [ ! -e "${partnerPath}/dists" ] || do_use_timestamp "$timestamp" 6 ; then
            # Construct all known URLs
            while read -r pathname
            do
                url="http://archive.canonical.com/$pathname"
                echo "$url" >> "${partner_files}.urls"
                echo "$partnerPath/$pathname" >> "${partner_files}.all"
            done < <(cat "$partner_files")

            args="-N -x -nH"
            if [ "$verbose" = "yes" ]; then
                if [ "$very_verbose" = "yes" ]; then
                    args="$args -v"
                else
                    args="$args -nv"
                fi
            else
                args="$args -q"
            fi

            set +e
            wget $args -i "${partner_files}.urls" -P "$partnerPath"
            rc=$?
            set -e
            # exit 8 is 404, which we're going to see a lot of. :)
            if [ "$rc" -ne 0 ] && [ "$rc" -ne 8 ]; then
                echo "wget failed" >&2
                exit 1
            fi

            # TODO: uncompress here?

            # Clean up?
            do_cleanup "${partner_files}.all" "$partnerPath"

            if [ "$dry_run" != "yes" ]; then
                if [ "$use_timestamp" = "yes" ]; then
                    touch "$timestamp"
                else
                    rm -f "$timestamp"
                fi
            fi
        fi
    fi
fi

if [ "$pull_debian" = "yes" ]; then
    # Sync Sources from Debian testing
    timestamp="${debianPath}.timestamp"
    if [ ! -e "${debianPath}/dists" ] || do_use_timestamp "$timestamp" 6 ; then
        debian_files="$workdir/debian"

        if [ "$verbose" = "yes" ]; then
            echo "Generating debian source lists"
        fi

        # dists/testing/main/source/Sources.xz
        for i in main contrib non-free
        do
            spew_src_lines testing $i >>"$debian_files"
        done

        pull_packages "$debian_files" "rsync://$debian_archive/debian/" "$debianPath" || echo "FAIL: debian sources" >&2

        # TODO: uncompress here?

        # Clean up?
        do_cleanup "${debian_files}.all" "$debianPath"

        if [ "$dry_run" != "yes" ]; then
            if [ "$use_timestamp" = "yes" ]; then
                touch "$timestamp"
            else
                rm -f "$timestamp"
            fi
        fi
    fi
fi

# generate source package lists for umt grep
for path in "$ubuntuPath" "$debianPath" "$partnerPath"; do
  find $path -name Sources.gz -exec zgrep '^Package: .*' {} \; | cut -c10- | sort -u > $path/sources
done
