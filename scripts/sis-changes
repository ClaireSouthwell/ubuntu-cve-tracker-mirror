#!/usr/bin/env python
# Copyright 2007-2009, Canonical, Ltd.
# Author: Kees Cook <kees@ubuntu.com>
#         Jamie Strandboge <jamie@canonical.com>
# License: GPLv3
#
# Extract/download list of changes file links from a given LP name, pkg, version
import sys, time, os.path, re
import urllib2, cookielib
import libxml2
import optparse
import tempfile, shutil
import cve_lib
import copy
try:
    import lpl_common
except:
    print >>sys.stderr, "lpl_common.py seems to be missing.  Please create a symlink from $UQT/common/lpl_common.py to $UCT/scripts/"
    sys.exit(1)

def xmlurl(url):
    # Get the HTML
    tries = 0
    max_tries = 5
    while True:
        try:
            doc = opener.open(url).read()
            # Parse into XML tree
            if '<title>Log in or register with Launchpad' in doc:
                err = urllib2.HTTPError("Not logged into Launchpad")
                err.code = 502
                raise err
            return libxml2.htmlParseDoc(doc,None)
        except urllib2.HTTPError, e:
            tries += 1
            if tries >= max_tries or e.code != 502:
                print >>sys.stderr, "Failed: %s" % (url)
                raise

            print >>sys.stderr, "Retrying: %s" % (url)
            time.sleep(3)

def download(url):
    # Download file to tmpdir
    if not os.path.exists(tmpdir):
        print >>sys.stderr, "Failed: '%s' does not exist" % (tmpdir)
        sys.exit(1)

    tries = 0
    max_tries = 10
    while True:
        try:
            page = opener.open(url)
            break
        except urllib2.HTTPError, e:
            tries += 1
            if tries >= max_tries or (e.code != 502 and e.code != 504 and e.code != 500):
                print >>sys.stderr, "Failed (%d): %s" % (e.code, url)
                raise

            print >>sys.stderr, "Retrying (%d): %s" % (e.code, url)
            time.sleep(3)

    name = os.path.join(tmpdir, os.path.basename(url))
    try:
        tmp, tmpname = tempfile.mkstemp()
    except Exception:
        raise
    os.write(tmp, page.read())
    os.close(tmp)
    os.rename(tmpname, name)
    return name

def download_url(url):
    '''Display URL, and optionally download it, if requested and matches the re'''
    filename = os.path.basename(url)
    if not opt.re or re.search(opt.re, filename):
        print url
        if opt.download:
            return download(url)
    return None


#
# START SCRIPT
#

parser = optparse.OptionParser()
parser.add_option("--action", help="What action to take: 'changes'(default), 'check-build', 'binaries', 'source', 'list'", metavar="NAME", action='store', default='changes')
parser.add_option("--ppa", help="Which PPA to use (default is 'ubuntu-security/ppa')", metavar="PERSON[/PPA]", action='store', default='ubuntu-security/ppa')
parser.add_option("--superseded-name", help="Name of superseded source package", metavar="SRCPKG", action='store')
parser.add_option("--superseded-version", help="Version of superseded files", metavar="NAME", action='store')
parser.add_option("--debug", help="Show debug output", action='store_true')
parser.add_option("--verbose", help="Verbose output", action='store_true')
parser.add_option("--lpnet", help="Use lpnet instead of edge for LP API", action='store_true', default=False)
parser.add_option("--beta", help="Use beta API instead of 1.0 LP API", action='store_true', default=False)
parser.add_option("-r","--release", help="Limit to a specific set of comma-separate releases", metavar="SERIES", action='store', default=None)

# Action-specific options
#   'changes'
parser.add_option("--dsc", help="Toggle fetching source .dsc files (default is True)", action='store_false', default=True)
#   'binaries'
parser.add_option("--arch", help="Limit 'binaries' and 'changes' action to comma-separated list of archs", metavar="ARCH[,ARCH...]", action='store')
parser.add_option("--re", help="When handling binaries, only include those matching this regular expression", metavar="RE", action='store')
#   'changes', 'binaries', 'source'
parser.add_option("--download", help="Download to DIR", metavar="DIR", action='store', default='')
parser.add_option("--force-download", help="Force download to DIR if it exists (removes old DIR)", action='store_true', default=False)
#   'source'
parser.add_option("--fetch-orig", help="Download the orig.tar.gz when fetching source", action='store_true', default=False)
#   'include-devel'
parser.add_option("--include-devel", help="Include development release", action='store_true', default=False)
parser.add_option("--include-eol", help="Include end of life releases", action='store_true', default=False)

(opt, args) = parser.parse_args()

# Load configuration
cve_lib.read_config()

# API interface
lp = lpl_common.connect(not opt.lpnet, beta=opt.beta)

# Get authenticated URL fetcher
opener = lpl_common.opener_with_cookie(cve_lib.config["plb_authentication"])
if not opener:
    raise ValueError, "Could not open cookies"

# slience parse warnings (from launchpad-python-bugs)
def noerr(ctx, str):
    pass
libxml2.registerErrorHandler(noerr, None)

if len(args)<1 and not opt.superseded_name:
    print "Usage: %s [--download <dir>] SRCPKG" % (sys.argv[0])
    sys.exit(1)

serieses = []
if opt.release:
    for r in opt.release.split(','):
        serieses.append(r.lower())

download_dir = ""
if opt.download:
    if opt.download == '':
        print >>sys.stderr, "Must specify a directory with '--download'"
        sys.exit(1)
    else:
        download_dir = opt.download
        if os.path.exists(download_dir):
            if opt.force_download:
                cve_lib.recursive_rm(download_dir)
            else:
                print >>sys.stderr, "'%s' exists. Please remove (or use --force-download) and try again." % (download_dir)
                sys.exit(1)
        tmpdir = tempfile.mkdtemp(dir='/tmp')

arch_list = [ 'amd64', 'i386', 'lpia', 'sparc', 'powerpc', 'hppa', 'ia64', 'armel' ]
releases = {
        'dapper': {
                'required': [ 'amd64', 'i386', 'sparc', 'powerpc' ],
                'expected': [ 'ia64', 'hppa' ],
                'bonus': [ ],
                },
        'edgy': {
                'required': [ 'amd64', 'i386', 'sparc', 'powerpc' ],
                'expected': [ ],
                'bonus': [ 'ia64', 'hppa' ],
                },
        'feisty': {
                'required': [ 'amd64', 'i386', 'sparc' ],
                'expected': [ 'powerpc' ],
                'bonus': [ 'hppa' ],
                },
        'gutsy': {
                'required': [ 'amd64', 'i386', 'sparc' ],
                'expected': [ 'powerpc', 'hppa', 'lpia' ],
                'bonus': [ ],
                },
        'hardy': {
                'required': [ 'amd64', 'i386', 'lpia' ],
                'expected': [ 'powerpc', 'hppa', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        'intrepid': {
                'required': [ 'amd64', 'i386', 'lpia' ],
                'expected': [ 'powerpc', 'hppa', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        'jaunty': {
                'required': [ 'amd64', 'i386' ],
                'expected': [ 'lpia', 'powerpc', 'hppa', 'sparc', 'armel' ],
                'bonus': [ 'ia64' ],
                },
        'karmic': {
                'required': [ 'amd64', 'i386', 'armel' ],
                'expected': [ 'lpia', 'powerpc', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        'lucid': {
                'required': [ 'amd64', 'i386', 'armel' ],
                'expected': [ 'powerpc', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        #'maverick': {
        #        'required': [ 'amd64', 'i386', 'armel' ],
        #        'expected': [ 'powerpc', 'sparc' ],
        #        'bonus': [ 'ia64' ],
        #        },
}

# pkg -> { release, release -> { version } }
def load_pkg_details_from_lp(pkgs, pkg, item):

    rel = item.distro_series.name
    if rel not in cve_lib.releases:
        raise ValueError, "Unknown release '%s':\n" % (rel) + head.content

    if serieses and rel not in serieses:
        if opt.debug:
            print >>sys.stderr, "Skipping %s: not in %s" % (rel, serieses)
        return

    version = item.source_package_version
    if opt.superseded_version and version != opt.superseded_version:
        print >>sys.stderr, "Skipping %s: %s %s (we need %s)" % (rel, pkg, version, opt.superseded_version)
        return

    pkgs.setdefault(pkg, dict())
    pkgs[pkg].setdefault(rel, dict())
    if opt.debug:
        print >>sys.stderr, "Source(%s): %s %s" % (rel, pkg, version)

    # Source details
    pkgs[pkg][rel].setdefault('source', dict())
    pkgs[pkg][rel]['source'].setdefault('version', version)

    # Handle transition to method (LP: #474876)
    if hasattr(item,'changes_file_url'):
        src_changes = item.changes_file_url
    else:
        src_changes = item.changesFileUrl()

    pkgs[pkg][rel]['source'].setdefault('changes', src_changes)
    if opt.debug:
        print >>sys.stderr, "Source(%s) changes: %s" % (rel, src_changes)

    # Get per-build items
    for build in item.getBuilds():
        arch = build.arch_tag
        pkgs[pkg][rel].setdefault(arch, dict())
        state = build.buildstate
        if opt.debug:
            print >>sys.stderr, "Build(%s,%s) %s" % (rel, arch, state)
        # Work around LP: #559591
        if state == 'Successful build':
            state = 'Successfully built'
        pkgs[pkg][rel][arch].setdefault('build_state', state)
        build_url = str(build)
        # Rewrite build URL from API to LP
        # https://api.edge.launchpad.net/beta/~ubuntu-security/+archive/ppa/+build/1402604
        # vs
        # https://edge.launchpad.net/~ubuntu-security/+archive/ppa/+build/1402604
        api_str = '1.0'
        if opt.beta:
            api_str = 'beta'
        build_url = build_url.replace('//api.','//').replace('launchpad.net/%s/' % (api_str),'launchpad.net/')
        if opt.debug:
            print >>sys.stderr, "Build URL(%s,%s) %s" % (rel, arch, build_url)
        pkgs[pkg][rel][arch].setdefault('build', build_url)

#    # Diff
#    for diff_a in diff_as:
#        diff_url = normalize_url(diff_a.prop('href'))
#        pkgs[pkg][rel]['source'].setdefault('ancestor-diff', diff_url)
#        if opt.debug:
#            print >>sys.stderr, "Diff(%s) URL: %s" % (rel, diff_url)

    # Binary outputs
    # Handle transition to method (LP: #474876)
    if hasattr(item,'binary_file_url'):
        bin_files = item.binary_file_urls
    else:
        bin_files = item.binaryFileUrls()
    for file_url in bin_files:
        if file_url.endswith('deb'):
            arch = file_url.split('_').pop().split('.')[0]
            # hack for "all": attach to i386
            if arch == 'all':
                arch = 'i386'
            pkgs[pkg][rel][arch].setdefault('binaries', dict())
            name = file_url.split('_')[-3].split('/').pop()
            pkgs[pkg][rel][arch]['binaries'].setdefault(name, file_url)
            if opt.debug:
                print >>sys.stderr, "Binary(%s,%s) URL: %s" % (rel, arch, file_url)
        else:
            raise ValueError, "Unknown downloadable binary file from %s %s '%s'" % (pkg, version, file_url)

    # Source inputs
    # Handle transition to method (LP: #474876)
    if hasattr(item,'source_file_url'):
        src_files = item.source_file_urls
    else:
        src_files = item.sourceFileUrls()
    for file_url in src_files:
        if file_url.endswith('.diff.gz'):
            pkgs[pkg][rel]['source'].setdefault('diff', file_url)
            if opt.debug:
                print >>sys.stderr, "Source(%s) diff.gz URL: %s" % (rel, file_url)
        elif file_url.endswith('.debian.tar.bz2'):
            pkgs[pkg][rel]['source'].setdefault('diff', file_url)
            if opt.debug:
                print >>sys.stderr, "Source(%s) debian.tar.bz2 URL: %s" % (rel, file_url)
        elif file_url.endswith('.dsc'):
            pkgs[pkg][rel]['source'].setdefault('dsc', file_url)
            if opt.debug:
                print >>sys.stderr, "Source(%s) dsc URL: %s" % (rel, file_url)
        elif file_url.endswith('.tar.gz'):
            pkgs[pkg][rel]['source'].setdefault('orig', file_url)
            if opt.debug:
                print >>sys.stderr, "Source(%s) .tar.gz URL: %s" % (rel, file_url)
        elif file_url.endswith('.orig.tar.bz2'):
            pkgs[pkg][rel]['source'].setdefault('orig', file_url)
            if opt.debug:
                print >>sys.stderr, "Source(%s) orig.tar.bz2 URL: %s" % (rel, file_url)
        else:
            raise ValueError, "Unknown downloadable source file from %s %s '%s'" % (pkg, version, file_url)

    # Check that all built binaries have actually published into the PPA
    for binary in item.getPublishedBinaries():
        if binary.status != 'Published':
            if opt.debug:
                print >>sys.stderr, "BinaryPublication(%s,%s,%s) state: %s" % (rel, binary.distro_arch_series.architecture_tag, binary.binary_package_name, binary.status)
            arch = binary.distro_arch_series.architecture_tag
            pkgs[pkg][rel][arch]['build_state'] = 'Binaries pending'


archive, group, ppa = lpl_common.get_archive(opt.ppa, lp, opt.debug, distribution=None)

pkgs = dict()
if opt.superseded_version:
    status = "Superseded"
else:
    status = "Published"
for pkg_name in args:
    for item in archive.getPublishedSources(source_name=pkg_name,
                                            exact_match=True,
                                            status=status):
        load_pkg_details_from_lp(pkgs, pkg_name, item)

if opt.action == 'changes':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)

        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            if not opt.include_eol and rel in cve_lib.eol_releases:
                print >>sys.stderr, "Skipping '%s' (use --include-eol)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']
            if ':' in version and not version.endswith(':'):
                # strip out epoch, if it exists
                version = version[(version.find(':')+1):]

            if opt.debug:
                print >>sys.stderr, "Fetching %s %s ..." % (pkg, version)

            changes_filepath = download_url(pkgs[pkg][rel]['source']['changes'])

            if opt.dsc:
                download_url(pkgs[pkg][rel]['source']['dsc'])

            archs = sorted(pkgs[pkg][rel].keys())
            if opt.arch:
                archs = archlist = opt.arch.split(',')

            for arch in archs:
                # Ignore 'source' and 'item' for build states
                if arch in ['source','item']:
                    continue
                if pkgs[pkg][rel][arch]['build_state'] != 'Successfully built':
                    print >>sys.stderr, "Skipping '%s' build for %s %s %s" % (pkgs[pkg][rel][arch]['build_state'], pkg,rel,arch)
                    continue
                if opt.debug:
                    print >>sys.stderr, "Loading build log for %s %s %s" % (pkg,rel,arch)

                # FIXME: scraping still!
                build_xml = xmlurl(pkgs[pkg][rel][arch]['build'])
                snippet = "/%s_%s_" % (pkg, version)
                if opt.debug:
                    print >>sys.stderr, "Screen scraping for '%s'" % (snippet)

                try:
                    changes_url = build_xml.xpathEval('//a[contains(@href,"%s")]' % (snippet))[0].prop('href')
                except:
                    if 'action="https://login.launchpad.net/+openid"' in str(build_xml):
                        raise ValueError, "%s %s %s %s.changes does not exist\nLP credentials may be out of date:\n%s" % (pkg, rel, version, arch, build_xml)
                    else:
                        raise ValueError, "%s %s %s %s.changes does not exist in:\n%s" % (pkg, rel, version, arch, str(build_xml))

                download_url(changes_url)

elif opt.action == 'binaries':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            if not opt.include_eol and rel in cve_lib.eol_releases:
                print >>sys.stderr, "Skipping '%s' (use --include-eol)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']
            archlist = sorted(pkgs[pkg][rel].keys())
            if opt.arch:
                archlist = opt.arch.split(',')
            for arch in archlist:
                if not pkgs[pkg][rel].has_key(arch):
                    continue
                if not pkgs[pkg][rel][arch].has_key('binaries'):
                    continue
                for name in sorted(pkgs[pkg][rel][arch]['binaries'].keys()):
                    download_url(pkgs[pkg][rel][arch]['binaries'][name])

elif opt.action == 'list':
    for pkg in sorted(pkgs.keys()):
        print pkg

elif opt.action == 'source':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            if not opt.include_eol and rel in cve_lib.eol_releases:
                print >>sys.stderr, "Skipping '%s' (use --include-eol)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']
            download_url(pkgs[pkg][rel]['source']['dsc'])
            if pkgs[pkg][rel]['source'].has_key('diff'):
                download_url(pkgs[pkg][rel]['source']['diff'])
            if not pkgs[pkg][rel]['source'].has_key('diff') or opt.fetch_orig:
                download_url(pkgs[pkg][rel]['source']['tar.gz'])

elif opt.action == 'check-build':
    EXIT_OKAY = 0
    EXIT_FAIL = 1
    exit_code = EXIT_OKAY
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        found = dict()

        suffix = ""
        if len(args)>1:
            suffix = " (%s)" % (pkg)

        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            if not opt.include_eol and rel in cve_lib.eol_releases:
                print >>sys.stderr, "Skipping '%s' (use --include-eol)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']
            found.setdefault(rel,dict())
            for arch in arch_list:
                found[rel].setdefault(arch,False)
                if pkgs[pkg][rel].has_key(arch):
                    state = pkgs[pkg][rel][arch]['build_state']
                    if state == 'Successfully built':
                        found[rel][arch] = True
                        if opt.verbose:
                            print '\t%s %s Built' % (rel, arch)

        code = EXIT_OKAY
        report_rel = []

        for rel in cve_lib.releases:
            complete = 1
            # Skip missing source.changes
            if not rel in found.keys():
                continue

            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            if not opt.include_eol and rel in cve_lib.eol_releases:
                print >>sys.stderr, "Skipping '%s' (use --include-eol)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']

            def drop_support(supported, arches):
                for drop_arch in arches:
                    for area in ['expected','required']:
                        if drop_arch in supported[area]:
                            supported[area].remove(drop_arch)
                            supported['bonus'].append(drop_arch)

            support = copy.deepcopy(releases[rel])
            # Special-case the split kernel in intrepid and later
            if re.match('linux(-meta|-source-2.6.15|-(backports|ubuntu|restricted)-modules(-2.6.[0-9]+)?)?$', pkg):
                if 'lpia' in support['required'] and rel not in ['hardy']:
                    drop_support(support,['lpia'])
                # Non-Dapper and Non-Hardy does not build sparc, ppc, hppa
                if rel not in ['dapper','hardy']:
                    drop_support(support, ['sparc','powerpc','hppa'])
                # Intrepid does not build armel or ia64
                if rel not in ['intrepid']:
                    drop_support(support, ['lpia','ia64'])
                # Jaunty does not build armel or ia64
                if rel not in ['jaunty']:
                    drop_support(support, ['armel','ia64'])
            if re.match('linux-(|meta-)ec2$', pkg):
                # EC2 is i386/amd64 only
                drop_support(support, ['sparc','powerpc','lpia','armel'])
            if re.match('linux-(|meta-)(fsl-imx51|mvl-dove|ti-omap|qcm-msm)$', pkg):
                # ARM kernels are, shockingly, ARM-only
                drop_support(support, ['sparc','powerpc','lpia','i386','amd64'])

            # Detect the "all" case -- only i386 in the build record
            if pkgs[pkg][rel].has_key('i386') and pkgs[pkg][rel].has_key('source') and len(pkgs[pkg][rel].keys())==2:
                support['bonus'] = []
                support['expected'] = []
                support['required'] = ['i386']

            for arch in arch_list:
                if arch in support['required'] and not found[rel][arch]:
                    build_state = "[no build for %s]" % (arch)
                    if pkgs[pkg][rel].has_key(arch):
                        build_state = pkgs[pkg][rel][arch]['build_state']
                    print >>sys.stderr, 'ERROR: %s missing for %s (%s)' % (arch, rel, build_state) + suffix
                    code = EXIT_FAIL
                    complete = 0
            for arch in arch_list:
                if arch in support['expected'] and not found[rel][arch]:
                    build_state = "[no build for %s]" % (arch)
                    if pkgs[pkg][rel].has_key(arch):
                        build_state = pkgs[pkg][rel][arch]['build_state']
                    print >>sys.stderr, 'WARN: %s missing for %s (%s)' % (arch, rel, build_state) + suffix
            for arch in arch_list:
                if arch in support['bonus'] and found[rel][arch]:
                    print >>sys.stderr, 'BONUS: %s found for %s' % (arch, rel) + suffix
            if complete:
                report_rel.append(rel)

        if code == EXIT_OKAY:
            print "OK: " + " ".join(report_rel) + suffix
        else:
            if len(report_rel):
                print "READY: " + " ".join(report_rel) + suffix
            print "FAIL: not all releases ready" + suffix
            print "*** DO NOT PUBLISH YET *** There is no method to unembargo an architecture later"
            exit_code = EXIT_FAIL
    sys.exit(exit_code)

else:
    print >>sys.stderr, "Unknown action '%s'" % (opt.action)
    sys.exit(1)

if opt.download:
    # Can't use os.rename because of potential for:
    # OSError: [Errno 18] Invalid cross-device link'
    shutil.move(tmpdir, download_dir)
    print "Files downloaded to %s" % (download_dir)
