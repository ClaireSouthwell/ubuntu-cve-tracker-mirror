#!/usr/bin/env python
# Copyright 2007-2008, Canonical, Ltd.
# Author: Kees Cook <kees@ubuntu.com>
#         Jamie Strandboge <jamie@canonical.com>
# License: GPLv3
#
# Extract/download list of changes file links from a given LP name, pkg, version
import sys, time, os.path, re
import urllib2, cookielib
import libxml2
import optparse
import tempfile, shutil
import cve_lib
from launchpadbugs import http_connection

cve_lib.read_config()

cookie_processor = http_connection.LPCookieProcessor()
cookie_processor.load_file(cve_lib.config["plb_authentication"])
opener = urllib2.build_opener(cookie_processor)

# slience parse warnings (from launchpad-python-bugs)
def noerr(ctx, str):
    pass
libxml2.registerErrorHandler(noerr, None)

def xmlurl(url):
    # Get the HTML
    tries = 0
    max_tries = 5
    while True:
        try:
            doc = opener.open(url).read()
            # Parse into XML tree
            return libxml2.htmlParseDoc(doc,None)
        except urllib2.URLError, e:
            tries += 1
            if tries >= max_tries or e.code != 502:
                print >>sys.stderr, "Failed: %s" % (url)
                raise

            if e.code == 502:
                print >>sys.stderr, "Retrying: %s" % (url)
                time.sleep(3)

def download(url):
    # Download file to tmpdir
    if not os.path.exists(tmpdir):
        print >>sys.stderr, "Failed: '%s' does not exist" % (tmpdir)
        sys.exit(1)

    tries = 0
    max_tries = 5
    while True:
        try:
            page = opener.open(url)
            break
        except urllib2.URLError, e:
            tries += 1
            if tries >= max_tries or e.code != 502:
                print >>sys.stderr, "Failed: %s" % (url)
                raise

            if e.code == 502:
                print >>sys.stderr, "Retrying: %s" % (url)
                time.sleep(3)

    name = os.path.join(tmpdir, os.path.basename(url))
    try:
        tmp, tmpname = tempfile.mkstemp()
    except Exception:
        raise
    os.write(tmp, page.read())
    os.close(tmp)
    os.rename(tmpname, name)

def download_url(url):
    '''Display URL, and optionally download it, if requested and matches the re'''
    filename = os.path.basename(url)
    if not opt.re or re.search(opt.re, filename):
        print url
        if opt.download:
            download(url)

parser = optparse.OptionParser()
parser.add_option("--action", help="What action to take: 'changes'(default), 'check-build', 'binaries', 'source', 'list'", metavar="NAME", action='store', default='changes')
parser.add_option("--ppa", help="Which group's PPA to use (default is 'ubuntu-security')", metavar="GROUP", action='store', default='ubuntu-security')
parser.add_option("--debug", help="Verbose processing output", action='store_true')
# Action-specific options
#   'changes'
parser.add_option("--dsc", help="Toggle fetching source .dsc files (default is True)", action='store_false', default=True)
#   'binaries'
parser.add_option("--arch", help="Limit 'binaries' and 'changes' action to comma-separated list of archs", metavar="ARCH[,ARCH...]", action='store')
parser.add_option("--re", help="When handling binaries, only include those matching this regular expression", metavar="RE", action='store')
#   'changes', 'binaries', 'source'
parser.add_option("--download", help="Download to DIR", metavar="DIR", action='store', default='')
parser.add_option("--force-download", help="Force download to DIR if it exists (removes old DIR)", action='store_true', default=False)
#   'source'
parser.add_option("--fetch-orig", help="Download the orig.tar.gz when fetching source", action='store_true', default=False)
#   'include-devel'
parser.add_option("--include-devel", help="Include development release", action='store_true', default=False)

# workaround for bug #302116
parser.add_option("--batch", help="Batch NUM queries", metavar="NUM", action='store', default='')
parser.add_option("--start-index", help="Start batch from NUM index", metavar="NUM", action='store', default='')


(opt, args) = parser.parse_args()

if len(args)<1:
    print "Usage: %s [--download <dir>] SRCPKG" % (sys.argv[0])
    sys.exit(1)

download_dir = ""
if opt.download:
    if opt.download == '':
        print >>sys.stderr, "Must specify a directory with '--download'"
        sys.exit(1)
    else:
        download_dir = opt.download
        if os.path.exists(download_dir):
            if opt.force_download:
                cve_lib.recursive_rm(download_dir)
            else:
                print >>sys.stderr, "'%s' exists. Please remove (or use --force-download) and try again." % (download_dir)
                sys.exit(1)
        tmpdir = tempfile.mkdtemp(dir='/tmp')

arch_list = [ 'amd64', 'i386', 'lpia', 'sparc', 'powerpc', 'hppa', 'ia64', 'armel' ]
releases = {
        'dapper': {
                'required': [ 'amd64', 'i386', 'sparc', 'powerpc' ],
                'expected': [ 'ia64', 'hppa' ],
                'bonus': [ ],
                },
        'edgy': {
                'required': [ 'amd64', 'i386', 'sparc', 'powerpc' ],
                'expected': [ ],
                'bonus': [ 'ia64', 'hppa' ],
                },
        'feisty': {
                'required': [ 'amd64', 'i386', 'sparc' ],
                'expected': [ 'powerpc' ],
                'bonus': [ 'hppa' ],
                },
        'gutsy': {
                'required': [ 'amd64', 'i386', 'sparc' ],
                'expected': [ 'powerpc', 'hppa', 'lpia' ],
                'bonus': [ ],
                },
        'hardy': {
                'required': [ 'amd64', 'i386', 'lpia' ],
                'expected': [ 'powerpc', 'hppa', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        'intrepid': {
                'required': [ 'amd64', 'i386', 'lpia' ],
                'expected': [ 'powerpc', 'hppa', 'sparc' ],
                'bonus': [ 'ia64' ],
                },
        'jaunty': {
                'required': [ 'amd64', 'i386' ],
                'expected': [ 'lpia', 'powerpc', 'hppa', 'sparc', 'armel' ],
                'bonus': [ 'ia64' ],
                },
}

base_url = 'https://launchpad.net'
ppa_url = '%s/~%s/+archive/ppa' % (base_url, opt.ppa)

ppa_url_list = ppa_url
if opt.batch and opt.start_index:
    ppa_url_list = '%s/+index?start=%d&batch=%d' % (ppa_url, \
              int(opt.start_index), int(opt.batch))

if opt.debug:
    print >>sys.stderr, "ppa_url = '%s'" % (ppa_url_list)

ppa_xml = xmlurl(ppa_url_list)
try:
    packages_list = ppa_xml.xpathEval("//table[@id='packages_list']")[0]
except:
    print >>sys.stderr, "Failed:\n" + ppa_xml.content
    raise

def normalize_url(url):
    if url.startswith('/'):
        url = base_url + url
    if url.startswith('+'):
        url = ppa_url + '/' + url
    return url

# pkg -> { release, release -> { version } }
pkgs = dict()
def load_pkg_details_from_xml(pkgs, xml):
    name = xml.xpathEval('self::tr/td[1]')[0].content.strip()
    pkg, version = name.split(' - ')
    rel  = xml.xpathEval('self::tr/td[6]')[0].content.strip().lower()
    if rel not in cve_lib.releases:
        raise ValueError, "Unknown release '%s':\n" % (rel) + head.content
    detail = xml.xpathEval('self::tr/following-sibling::tr[1]')[0]

    pkgs.setdefault(pkg, dict())
    pkgs[pkg].setdefault(rel, dict())
    if opt.debug:
        print >>sys.stderr, "Source(%s): %s %s" % (rel, pkg, version)

    # Source details
    pkgs[pkg][rel].setdefault('source', dict())
    pkgs[pkg][rel]['source'].setdefault('version', version)
    src_changes = xml.xpathEval('self::tr//a[contains(@href,"_source.changes")]')[0].prop('href')
    pkgs[pkg][rel]['source'].setdefault('changes', normalize_url(src_changes))
    if opt.debug:
        print >>sys.stderr, "Source(%s) changes: %s" % (rel, src_changes)

    # Build details
    build_lis = detail.xpathEval('self::tr//h3[.="Builds"]/following-sibling::ul[1]//li')
    diff_as =   detail.xpathEval('self::tr//h3[.="Available diffs"]/following-sibling::ul[1]//a')
    file_as =   detail.xpathEval('self::tr//h3[.="Download files from Librarian"]/following-sibling::ul//a')
    if len(build_lis) == 0:
        # Handle secondary-fetches of build details
        pub_id = int(detail.prop('id').split('pub')[1])
        ## load detail
        # e.g. https://edge.launchpad.net/%7Eubuntu-security/+archive/ppa/+sourcepub/491503/+listing-archive-extra
        pub_url = ppa_url+'/+sourcepub/%d/+listing-archive-extra'% (pub_id)
        if opt.debug:
            print >>sys.stderr, "pub_url = '%s'" % (pub_url)
        detail = xmlurl(pub_url)
        ## re-search for build_lis
        build_lis = detail.xpathEval('//h3[.="Builds"]/following-sibling::ul[1]//li')
        diff_as =   detail.xpathEval('//h3[.="Available diffs"]/following-sibling::ul[1]//a')
        file_as =   detail.xpathEval('//h3[.="Package files"]/following-sibling::ul//a')
        if len(build_lis) == 0:
            raise ValueError, "Failed to fetch publication details for %s/%s (%s)" % (pkg, rel, pub_id)

    for build_li in build_lis:
        build_a = build_li.xpathEval('self::li/a')[0]
        build_url = normalize_url(build_a.prop('href'))
        arch = build_a.content.strip().lower()
        pkgs[pkg][rel].setdefault(arch, dict())
        pkgs[pkg][rel][arch].setdefault('build', build_url)

        build_img = build_li.xpathEval('self::li/img')[0]
        state = build_img.prop('src').split('-')[1]
        pkgs[pkg][rel][arch].setdefault('build_state', state)

        if opt.debug:
            print >>sys.stderr, "Build(%s,%s) %s URL: %s" % (rel, arch, state, build_url)

    # Diff
    for diff_a in diff_as:
        diff_url = normalize_url(diff_a.prop('href'))
        pkgs[pkg][rel]['source'].setdefault('ancestor-diff', diff_url)
        if opt.debug:
            print >>sys.stderr, "Diff(%s) URL: %s" % (rel, diff_url)

    # Files
    for file_a in file_as:
        file_url = normalize_url(file_a.prop('href'))
        #if opt.debug:
        #    print >>sys.stderr, "package file(%s/%s): %s" % (pkg, rel, file_url)
        if file_url.endswith('deb'):
            arch = file_url.split('_').pop().split('.')[0]
            # hack for "all": attach to i386
            if arch == 'all':
                arch = 'i386'
            pkgs[pkg][rel][arch].setdefault('binaries', dict())
            name = file_url.split('_')[-3].split('/').pop()
            pkgs[pkg][rel][arch]['binaries'].setdefault(name, file_url)
            if opt.debug:
                print >>sys.stderr, "Binary(%s,%s) URL: %s" % (rel, arch, file_url)
        else:
            if file_url.endswith('.diff.gz'):
                pkgs[pkg][rel]['source'].setdefault('diff', file_url)
                if opt.debug:
                    print >>sys.stderr, "diff.gz(%s,%s) URL: %s" % (rel, arch, file_url)
            elif file_url.endswith('.dsc'):
                pkgs[pkg][rel]['source'].setdefault('dsc', file_url)
                if opt.debug:
                    print >>sys.stderr, "dsc(%s,%s) URL: %s" % (rel, arch, file_url)
            elif file_url.endswith('.tar.gz'):
                pkgs[pkg][rel]['source'].setdefault('orig', file_url)
                if opt.debug:
                    print >>sys.stderr, "orig(%s,%s) URL: %s" % (rel, arch, file_url)
            else:
                raise ValueError, "Unknown downloadable file from %s %s '%s'" % (pkg, version, file_url)

for pkg_tr in packages_list.xpathEval('//tbody/tr[(@class = "archive_package_row") or (@class = "ppa_package_row")]'):
    load_pkg_details_from_xml(pkgs, pkg_tr)

if opt.action == 'changes':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)

        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            version = pkgs[pkg][rel]['source']['version']
            if ':' in version and not version.endswith(':'):
                # strip out epoch, if it exists
                version = version[(version.find(':')+1):]

            if opt.debug:
                print >>sys.stderr, "Fetching %s %s ..." % (pkg, version)

            if opt.dsc:
                download_url(pkgs[pkg][rel]['source']['dsc'])

            download_url(pkgs[pkg][rel]['source']['changes'])

            archs = sorted(pkgs[pkg][rel].keys())
            if opt.arch:
                archs = archlist = opt.arch.split(',')

            for arch in archs:
                # Ignore 'source' for build states
                if arch == 'source':
                    continue
                if pkgs[pkg][rel][arch]['build_state'] != 'success':
                    if opt.debug:
                        print >>sys.stderr, "Skipping '%s' build for %s %s %s" % (pkgs[pkg][rel][arch]['build_state'], pkg,rel,arch)
                    continue
                if opt.debug:
                    print >>sys.stderr, "Loading build log for %s %s %s" % (pkg,rel,arch)
                build_xml = xmlurl(pkgs[pkg][rel][arch]['build'])

                try:
                    changes_url = os.path.join(pkgs[pkg][rel][arch]['build'], build_xml.xpathEval('//a[contains(@href,"/%s_%s_")]' % (pkg, version))[0].prop('href'))
                except:
                    raise ValueError, "%s %s %s %s.changes does not exist" % (pkg, rel, version, arch)

                download_url(changes_url)

elif opt.action == 'binaries':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            archlist = sorted(pkgs[pkg][rel].keys())
            if opt.arch:
                archlist = opt.arch.split(',')
            for arch in archlist:
                if not pkgs[pkg][rel].has_key(arch):
                    continue
                if not pkgs[pkg][rel][arch].has_key('binaries'):
                    continue
                for name in sorted(pkgs[pkg][rel][arch]['binaries'].keys()):
                    download_url(pkgs[pkg][rel][arch]['binaries'][name])

elif opt.action == 'list':
    for pkg in sorted(pkgs.keys()):
        print pkg

elif opt.action == 'source':
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            download_url(pkgs[pkg][rel]['source']['dsc'])
            if pkgs[pkg][rel]['source'].has_key('diff'):
                download_url(pkgs[pkg][rel]['source']['diff'])
            if not pkgs[pkg][rel]['source'].has_key('diff') or opt.fetch_orig:
                download_url(pkgs[pkg][rel]['source']['tar.gz'])

elif opt.action == 'check-build':
    EXIT_OKAY = 0
    EXIT_FAIL = 1
    exit_code = EXIT_OKAY
    for pkg in args:
        if not pkgs.has_key(pkg):
            raise ValueError, "Source package '%s' not found in PPA" % (pkg)
        found = dict()

        for rel in sorted(pkgs[pkg].keys()):
            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue
            found.setdefault(rel,dict())
            for arch in arch_list:
                found[rel].setdefault(arch,False)
                if pkgs[pkg][rel].has_key(arch):
                    state = pkgs[pkg][rel][arch]['build_state']
                    if state == 'success':
                        found[rel][arch] = True

        code = EXIT_OKAY
        report_rel = []

        for rel in cve_lib.releases:
            complete = 1
            # Skip missing source.changes
            if not rel in found.keys():
                continue

            if not opt.include_devel and rel == cve_lib.devel_release:
                print >>sys.stderr, "Skipping '%s' (use --include-devel)" % (rel)
                continue

            support = releases[rel]
            # Special-case the split kernel in intrepid and later
            if (pkg == 'linux' or pkg.startswith('linux-')) and 'lpia' in support['required'] and rel not in ['hardy']:
                support['bonus'].append('lpia')
                support['required'].remove('lpia')
            # Detect the "all" case -- only i386 in the build record
            if pkgs[pkg][rel].has_key('i386') and pkgs[pkg][rel].has_key('source') and len(pkgs[pkg][rel].keys())==2:
                support['bonus'] = []
                support['expected'] = []
                support['required'] = ['i386']

            for arch in arch_list:
                if arch in support['required'] and not found[rel][arch]:
                    build_state = "missing"
                    if pkgs[pkg][rel].has_key(arch):
                        build_state = pkgs[pkg][rel][arch]['build_state']
                    print >>sys.stderr, 'ERROR: %s missing for %s (%s)' % (arch, rel, build_state)
                    code = EXIT_FAIL
                    complete = 0
            for arch in arch_list:
                if arch in support['expected'] and not found[rel][arch]:
                    build_state = "missing"
                    if pkgs[pkg][rel].has_key(arch):
                        build_state = pkgs[pkg][rel][arch]['build_state']
                    print >>sys.stderr, 'WARN: %s missing for %s (%s)' % (arch, rel, build_state)
            for arch in arch_list:
                if arch in support['bonus'] and found[rel][arch]:
                    print >>sys.stderr, 'BONUS: %s found for %s' % (arch, rel)
            if complete:
                report_rel.append(rel)

        if code == EXIT_OKAY:
            print "OK: " + " ".join(report_rel)
        else:
            if len(report_rel):
                print "READY: " + " ".join(report_rel)
            print "FAIL: not all releases ready"
            exit_code = EXIT_FAIL
    sys.exit(exit_code)

else:
    print >>sys.stderr, "Unknown action '%s'" % (opt.action)
    sys.exit(1)

if opt.download:
    # Can't use os.rename because of potential for:
    # OSError: [Errno 18] Invalid cross-device link'
    shutil.move(tmpdir, download_dir)
    print "Files downloaded to %s" % (download_dir)
